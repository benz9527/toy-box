# False Sharing

伪共享的非标准定义为：
缓存系统中是以缓存行（cache line）为单位存储的，当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。

缓存行上的写竞争是运行在 SMP 系统中并行线程实现可伸缩性最重要的限制因素。

## Cache Line

![cache line](./assets/cache-line.png)

比如 Go 一个 uint64 类型是 8 字节，因此在一个缓存行中可以存 8 个 uint64 类型的变量。

所以，如果你访问一个 uint64 数组，当数组中的一个值被加载到缓存中，它会额外加载另外 7 个，以致你能非常快地遍历这个数组。

事实上，你可以非常快速的遍历在连续的内存块中分配的任意数据结构。

但是如果你在数据结构中的项在内存中不是彼此相邻的（如链表），你将得不到免费缓存加载所带来的优势，并且在这些数据结构中的每一个项都可能会出现缓存未命中。

如果有多个线程操作不同的成员变量，但是相同的缓存行，就是发生了伪共享。

## 缓存命中耗时

![cache hit](./assets/martin-thompson-cache.png)

每个核心都有自己的缓存，如果另外的核心里面的线程需要跨核心访问数据，就需要通过 QPI（Intel QuickPath Interconnect）总线来访问，这个过程是非常耗时的。

https://www.intel.com/content/www/us/en/docs/programmable/683888/current/qpi-overview.html

简单地说就是需要 memory controller 的参与。

现在通常的做法是，被访问的数据会从核心1发送到核心2的缓存，然后核心2再从自己的缓存中读取数据，这样就避免了 QPI 总线的参与。

## MESI 协议 & RFO

### MESI

M（修改，Modified）：本地处理器已经修改缓存行，即是脏行，它的内容与内存中的内容不一样，并且此 cache 只有本地一个拷贝(专有)；
E（专有，Exclusive）：缓存行内容和内存中的一样，而且其它处理器都没有这行数据；
S（共享，Shared）：缓存行内容和内存中的一样, 有可能其它处理器也存在此缓存行的拷贝；
I（无效，Invalid）：缓存行失效, 不能使用。

![MESI状态转换](./assets/MESI-SM.png)

初始：一开始时，缓存行没有加载任何数据，所以它处于 I 状态。

本地写（Local Write）：如果本地处理器写数据至处于 I 状态的缓存行，则缓存行的状态变成 M。

本地读（Local Read）：如果本地处理器读取处于 I 状态的缓存行，很明显此缓存没有数据给它。此时分两种情况：(1)其它处理器的缓存里也没有此行数据，则从内存加载数据到此缓存行后，再将它设成 E 状态，表示只有我一家有这条数据，其它处理器都没有；(2)其它处理器的缓存有此行数据，则将此缓存行的状态设为 S 状态。（备注：如果处于M状态的缓存行，再由本地处理器写入/读出，状态是不会改变的）

远程读（Remote Read）：假设我们有两个处理器 c1 和 c2，如果 c2 需要读另外一个处理器 c1 的缓存行内容，c1 需要把它缓存行的内容通过内存控制器 (Memory Controller) 发送给 c2，c2 接到后将相应的缓存行状态设为 S。在设置之前，内存也得从总线上得到这份数据并保存。

远程写（Remote Write）：其实确切地说不是远程写，而是 c2 得到 c1 的数据后，不是为了读，而是为了写。也算是本地写，只是 c1 也拥有这份数据的拷贝，这该怎么办呢？c2 将发出一个 RFO (Request For Owner) 请求，它需要拥有这行数据的权限，其它处理器的相应缓存行设为 I，除了它自已，谁不能动这行数据。这保证了数据的安全，同时处理 RFO 请求以及设置I的过程将给写操作带来很大的性能消耗。


| 当前状态  | 触发事件 | 解释                                                               | 迁移状态 |
|-------|------|------------------------------------------------------------------|------|
| M 修改态 | 总线读  | 侦测到总线上有其他处理器在请求准备读取该行，刷新该行到内存，以方便其他处理能用到最新的数据，并更新状态为 S           | S    |
|       | 总线写  | 侦测到总线上有其他处理器试图请求来写该行（独占），刷新该行到内存，并设置本地的副本为 I 状态                  | I    |
|       | 处理器读 | 本地处理器对该行进行读操作，不需要改变状态                                            | M    |
|       | 处理器写 | 本地处理器对该行进行写操作，不需要改变状态                                            | M    |
| E 独占态 | 总线读  | 侦测到总线上有其他处理器在请求准备读取该行，因为本地处理器还没有对该行进行写操作，因此缓存内容与内存的一致，只需要改为 S 状态 | S    |
|       | 总线写  | 侦测到总线上有其他处理器试图请求来写该行（独占），设置为 I 状态                                | I    |
|       | 处理器读 | 本地处理器对该行进行读操作，不需要改变状态                                            | E    |
|       | 处理器写 | 本地处理器对该行进行写操作，需要进入 M 状态                                          | M    |
| S 共享态 | 总线读  | 侦测到总线上有其他处理器在请求准备读取该行，不需要改变状态                                    | S    |
|       | 总线写  | 侦测到总线上有其他处理器试图请求来写该行（独占），设置为 I 状态                                | I    |
|       | 处理器读 | 本地处理器对该行进行读操作，不需要改变状态                                            | S    |
|       | 处理器写 | 产生了一个试图写该行的信号到总线，需要进入 M 状态                                       | M    |
| I 无效态 | 总线读  | 侦测到总线上有其他处理器在请求准备读取该行，不需要改变状态                                    | I    |
|       | 总线写  | 侦测到总线上有其他处理器试图请求来写该行（独占），不需要改变状态                                 | I    |
|       | 处理器读 | Cache 不命中，产生一个读请求，送到总线上，内存数据到达 Cache 后进入 S 态                     | S    |
|       | 处理器写 | Cache 不命中，产生一个写请求，送到总线上，内存数据到达 Cache 后进入 M 态                     | M    |

### RFO

Request For Ownership 是一种缓存一致性协议，用于在多处理器系统中保持缓存的一致性。

前面第一张 cache line 的图中，如果不同核心的线程 1 和线程 2 都要修改同一个缓存行，但是(core1)线程 1 修改 X，(core2)线程 2 修改 Y，这两个频繁改动的变量都处于同一条缓存行。

两个线程就会轮番发送 RFO (缓存锁)，占得此缓存行的拥有权。

当 core1 取得了拥有权开始更新 X，则 core2 对应的缓存行需要设为 I 状态。

当 core2 取得了拥有权开始更新 Y，则 core1 对应的缓存行需要设为 I 状态(失效态)。

轮番夺取拥有权不但带来大量的 RFO 消息，而且如果某个线程需要读此行数据时，L1 和 L2 缓存上都是失效数据，只有 L3 缓存上是同步好的数据。

读 L3 的数据非常影响性能。更坏的情况是跨槽读取，L3 都要 miss，只能从内存上加载。

## 解决伪共享的思路

让不同的线程操作的对象处于不同的 cache line 中

使用 padding 的方式，占据空间，go 里面的结构没有 java 里面的对象头固定占 8 字节(32位系统)或 12 字节( 64 位系统默认开启压缩, 不开压缩为 16 字节)，直接填充空间即可。

隐蔽的伪共享问题，比如双向链表的哨兵头结点和尾结点，可能会被放在同一个缓存行中，在不断更新头尾指向（数据结点）的时候，这样会导致频繁的 RFO 消息。

# Memory Barrier

x86的lock#指令前缀（prefix）主要解决原子性（atomicity）的问题，同时隐含了内存屏障（memory barrier）。

相当于这条原子指令执行结束后，写到内存地址的内容是对其他核心都可见的。

还有其他方式是通过锁总线完成的。

https://www.kernel.org/doc/Documentation/memory-barriers.txt

- smp_wmb()
- smp_rmb()
- smp_mb()

# RingBuffer

- Circular Queue
- Cyclic Buffer
- Circular Buffer

固定大小的缓冲区，先进先出，新的数据会覆盖旧的数据。

要想存放变长数据类型，应当存放指针（引用类型）。

单生产-消费模式是无锁的（同一线程）

使用无符号整数，可以不用担心溢出问题，因为溢出后会自动从 0 开始（回绕）。

## Linux kfifo

## Linux eventfd